{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАГРУЗКА ДАННЫХ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка датасетов\n",
    "submission_data_test = pd.read_csv(r\"C:\\Users\\User\\Desktop\\test project\\submission_data_test.csv\")\n",
    "submission_data_train = pd.read_csv(r\"C:\\Users\\User\\Desktop\\test project\\submissions_data_train.csv\")\n",
    "events_data_test = pd.read_csv(r\"C:\\Users\\User\\Desktop\\test project\\events_data_test.csv\")\n",
    "events_data_train = pd.read_csv(r\"C:\\Users\\User\\Desktop\\test project\\event_data_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_data(data, days=2):\n",
    "    '''Фильтрация данных с порогом 2 дня от начала обучения'''\n",
    "\n",
    "    #Создаем колонку с первым действием пользователя\n",
    "    r_side_to_merge = data.groupby('user_id', as_index=False) \\\n",
    "                        .agg({'timestamp':'min'}) \\\n",
    "                        .rename({'timestamp':'min_timestamp'}, axis=1)\n",
    "    \n",
    "    #Объединяем и фильтруем по времени + 2 дня от даты старта\n",
    "    learning_time_threshold = days * 24 * 60 * 60\n",
    "    data = data.merge(r_side_to_merge, on='user_id', how='outer')\n",
    "    data = data[data.timestamp < (data.min_timestamp + learning_time_threshold)]\n",
    "    \n",
    "    #Проверяем что все пользователи на месте\n",
    "    assert data.user_id.nunique() == data.user_id.nunique()\n",
    "    return data.drop('min_timestamp', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_feature(submission_data, events_data):\n",
    "    '''Выделение в числовые признаки изначальные данные и объединение в одну таблицу'''\n",
    "    user_scores = submission_data.pivot_table(columns='submission_status', \n",
    "                                 values='step_id', \n",
    "                                 aggfunc='count', \n",
    "                                 index='user_id', \n",
    "                                 fill_value=0) \\\n",
    "                                .reset_index() \\\n",
    "                                .rename_axis('', axis=1)\n",
    "    users_events_data = events_data.pivot_table(columns='action', \n",
    "                             values='step_id', \n",
    "                             aggfunc='count', \n",
    "                             index='user_id',\n",
    "                             fill_value=0) \\\n",
    "                             .reset_index() \\\n",
    "                             .rename_axis('', axis=1)\n",
    "    \n",
    "    #Объединяем\n",
    "    users_data = user_scores.merge(users_events_data, \n",
    "                                           on='user_id', \n",
    "                                           how='outer') \\\n",
    "                                           .fillna(0)\n",
    "    \n",
    "    #Проверяем что все пользователи на остались в данных\n",
    "    assert events_data.user_id.nunique() == users_data.user_id.nunique()\n",
    "    return users_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(submission_data, threshold=40):\n",
    "    '''Создаем таргет для расчета что будет считаться успешным прохождением теста. По умолчанию принимаем 40 правильных ответов как условие прохождения\n",
    "    Значениsubmission_data_test['correct_num'].hist(bins=50)\n",
    "    '''\n",
    "\n",
    "    #Создаем колонку с количеством правильных ответов\n",
    "    users_count_correct = submission_data[submission_data['submission_status'] == 'correct'].groupby('user_id') \\\n",
    "                                            .agg({'submission_status':'count'}) \\\n",
    "                                            .reset_index()  \\\n",
    "                                            .rename({'submission_status':'correct_num'}, axis=1)\n",
    "    \n",
    "    #Фильтруем по ранее созданной колонке\n",
    "    users_count_correct['passed_course'] = (users_count_correct['correct_num'] > threshold).astype('int')\n",
    "    return users_count_correct.drop('correct_num', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_features(event_data):\n",
    "    '''Создаем колонку часов посвященных на обучению'''\n",
    "    events_data_train['date'] = pd.to_datetime(events_data_train['timestamp'], unit='s')\n",
    "    events_data_train['day'] = pd.to_datetime(events_data_train['timestamp'], unit='s').dt.date\n",
    "\n",
    "    users_time_feature = events_data_train.groupby('user_id') \\\n",
    "                                    .agg({'timestamp':['max', 'min'], 'day':'nunique'}) \\\n",
    "                                    .rename(columns={'nunique':'days'}) \\\n",
    "                                    .droplevel(0, axis=1) \\\n",
    "                                    .reset_index()\n",
    "\n",
    "    users_time_feature['hours'] = round((users_time_feature['max'] - users_time_feature['min']) / 3600, 1)\n",
    "    return users_time_feature.drop(['max', 'min'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tries_feature(submission_data):\n",
    "    submission_data = submission_data.groupby('user_id', as_index=False) \\\n",
    "                                    .agg({'step_id':'nunique'}) \\\n",
    "                                    .rename({'step_id':'steps_tried'}, axis=1)\n",
    "    return submission_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_ratio(submission_data):\n",
    "    '''Добавляем колонку соотношения верных и неверных ответов пользователя'''\n",
    "    submission_data['correct_ratio'] = submission_data['correct'] / (submission_data['correct'] + submission_data['wrong']).fillna(0)\n",
    "    return submission_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(submission_data, events_data):\n",
    "    '''Функция для формирования Х и у датасетов'''\n",
    "    # Фильтруем данные по первым 2 дням обучения для каждого студента\n",
    "    submission_data_2days = filtered_data(submission_data)\n",
    "    events_data_2days = filtered_data(events_data)\n",
    "\n",
    "    # Добавляем базовые признакми и объединяем в единую таблицу\n",
    "    users_data = create_base_feature(submission_data_2days, events_data_2days)\n",
    "\n",
    "    #Создаем целевую переменную Y\n",
    "    users_target_feature = create_target(submission_data, threshold=40)\n",
    "\n",
    "    #Создаем доп признаки по времени и соотношению правильных/неправильных ответов\n",
    "    time_column = time_features(events_data_2days)\n",
    "    users_steps_tried = tries_feature(submission_data_2days)\n",
    "    ratio_features = correct_ratio(users_data)\n",
    "\n",
    "    #Объединяем с основной таблицей дополнительные вычисленные признаки\n",
    "    first = users_data.merge(users_steps_tried, on='user_id', how='outer').fillna(0)\n",
    "    second = first.merge(time_column, on='user_id', how='outer').fillna(0)\n",
    "    third = second.merge(users_target_feature, on='user_id', how='outer').fillna(0)\n",
    "\n",
    "    #Создаем целевую переменную X\n",
    "    y = third['passed_course'].map(int)\n",
    "    X = third.drop(['passed_course'], axis=1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_df(submission_data, events_data):\n",
    "    '''Функция для формирования Х и у датасетов'''\n",
    "    # Фильтруем данные по первым 2 дням обучения для каждого студента\n",
    "    submissions_2days = filtered_data(submission_data)\n",
    "    events_2days = filtered_data(events_data)\n",
    "\n",
    "    # Добавляем базовые признакми и объединяем в единую таблицу\n",
    "    users_data = create_base_feature(submission_data, events_data)\n",
    "\n",
    "    #Создаем целевую переменную Y\n",
    "    y = create_target(submission_data, threshold=40)\n",
    "\n",
    "    #Создаем доп признаки по времени и соотношению правильных/неправильных ответов\n",
    "    users_time_feature = time_features(events_2days)\n",
    "    users_steps_tried = tries_feature(submissions_2days)\n",
    "    users_data = correct_ratio(users_data)\n",
    "\n",
    "    #Объединяем с основной таблицей дополнительные вычисленные признаки\n",
    "    first = users_data.merge(users_time_feature, on='user_id', how='outer').fillna(0)\n",
    "    X = first.merge(users_steps_tried, on='user_id', how='outer').fillna(0)\n",
    "\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание треннировочного и тестового датасетов\n",
    "X_train, y = create_df(submission_data_train, events_data_train)\n",
    "X_test = create_test_df(submission_data_test, events_data_test)\n",
    "\n",
    "#Приводим к одному порядку колонок\n",
    "X_test = X_test[['user_id', 'correct', 'wrong', 'discovered', 'passed',\n",
    "       'started_attempt', 'viewed', 'correct_ratio', 'steps_tried', 'days',\n",
    "       'hours']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_with_grid(train_data, y, size=0.20):\n",
    "    \n",
    "    \"\"\"Поиск наилучших параметров для RandomForest, обучаясь на тренировочной выборке.\n",
    "    Можно изменять или добавлять различные параметры. Может долго вычисляться.\"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, y, test_size=size, random_state=42)\n",
    "    \n",
    "    param_grid = {'randomforestclassifier__n_estimators': range(20, 51, 6), \n",
    "                  'randomforestclassifier__max_depth': range(5, 14),\n",
    "                  'randomforestclassifier__bootstrap': [True]}\n",
    "    \n",
    "    pipe = make_pipeline(RandomForestClassifier())\n",
    "    pipe.fit(X_train, y_train)\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"Наилучшие параметры: {grid.best_params_}\")\n",
    "    \n",
    "    ypred_prob = grid.predict_proba(X_test)\n",
    "    \n",
    "    roc_score = roc_auc_score(y_test, ypred_prob[:, 1])\n",
    "    score = grid.score(X_test, y_test)\n",
    "    print(f\"Правильность на тестовом наборе: {score:.2f}\")\n",
    "    print(f'ROC : {roc_score}')\n",
    "    \n",
    "    #Покажем наиболее влияющие параметры на предсказание\n",
    "    best_model = grid.best_estimator_.named_steps['randomforestclassifier']\n",
    "    value = pd.DataFrame({'parameters_name': list(X_test), \n",
    "                  'importance_%':best_model.feature_importances_}) \\\n",
    "                    .sort_values('importance_%',ascending=False) \\\n",
    "                        .iloc[:3] \\\n",
    "                        .set_index('parameters_name',drop=True) \\\n",
    "                        .mul(100) \\\n",
    "                        .round(1)\n",
    "    print(f'\\nНаиболее влияющие параметры \\n{value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие параметры: {'randomforestclassifier__bootstrap': True, 'randomforestclassifier__max_depth': 7, 'randomforestclassifier__n_estimators': 50}\n",
      "Правильность на тестовом наборе: 0.94\n",
      "roc_score 0.9719350687092623\n",
      "\n",
      "Наиболее влияющие параметры \n",
      "                 importance_%\n",
      "parameters_name              \n",
      "days                     40.4\n",
      "hours                    16.0\n",
      "steps_tried              14.0\n"
     ]
    }
   ],
   "source": [
    "random_with_grid(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_final(train_data, y, test_data, size=0.20):\n",
    "    \n",
    "    \"\"\"Финальное обучение на тренировочном датасете с лучшими параметрами и \n",
    "    получением predict_proba для тестового датасета с записей в csv файл\"\"\"\n",
    "    \n",
    "    test_data = test_data.sort_values('user_id')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, y.to_frame(), test_size=size, random_state=42)\n",
    "    \n",
    "    pipe = RandomForestClassifier(max_depth=7, n_estimators=32,  random_state=42)\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    ypred_prob = pipe.predict_proba(X_test)\n",
    "    \n",
    "    roc_score = roc_auc_score(y_test, ypred_prob[:, 1])\n",
    "    score = pipe.score(X_test, y_test)\n",
    "    print(f\"Правильность на валид наборе: {score:.3f}\")\n",
    "    print(f\"Roc_auc_score на валид наборе: {roc_score:.5f}\")\n",
    "    \n",
    "    ypred_prob_final = pipe.predict_proba(test_data)\n",
    "    result = test_data['user_id'].to_frame()\n",
    "    result['is_gone'] = ypred_prob_final[:, 1]\n",
    "    result[['user_id', 'is_gone']].to_csv(f'my_predict_{roc_score:.5f}.csv', index=False)\n",
    "    print(f'Результы записанны в файл my_predict_{roc_score:.5f}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на валид наборе: 0.942\n",
      "Roc_auc_score на валид наборе: 0.97187\n",
      "Результы записанны в файл my_predict_0.97187.csv\n"
     ]
    }
   ],
   "source": [
    "random_final(X_train, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
