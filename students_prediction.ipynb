{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАГРУЗКА ДАННЫХ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Загрузка датасетов\n",
    "submission_data_test = pd.read_csv(r\"C:\\Users\\User\\Desktop\\test project\\submission_data_test.csv\")\n",
    "submission_data_train = pd.read_csv(r\"C:\\Users\\User\\Desktop\\test project\\submissions_data_train.csv\")\n",
    "events_data_test = pd.read_csv(r\"C:\\Users\\User\\Desktop\\test project\\events_data_test.csv\")\n",
    "events_data_train = pd.read_csv(r\"C:\\Users\\User\\Desktop\\test project\\event_data_train.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_data(data, days=2):\n",
    "    '''Фильтрация данных с порогом 2 дня от начала обучения'''\n",
    "    data['timestamp'] = data['timestamp'].astype('datetime64[s]').dt.date\n",
    "\n",
    "    #Создаем колонку с первым действием пользователя\n",
    "    r_side_to_merge = data.groupby('user_id', as_index=False) \\\n",
    "                        .agg({'timestamp':'min'}) \\\n",
    "                        .rename({'timestamp':'min_timestamp'}, axis=1)\n",
    "    \n",
    "    #Объединяем и фильтруем по времени + 2 дня от даты старта\n",
    "    data = data.merge(r_side_to_merge, on='user_id', how='outer')\n",
    "    data = data[data.timestamp < data.min_timestamp + pd.DateOffset(days, 'D')]\n",
    "    \n",
    "    #Проверяем что все пользователи на месте\n",
    "    assert data.user_id.nunique() == data.user_id.nunique()\n",
    "    return data.drop('min_timestamp', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_feature(submission_data, events_data):\n",
    "    '''Выделение в числовые признаки изначальные данные и объединение в одну таблицу'''\n",
    "    submission_data = submission_data.pivot_table(columns='submission_status', \n",
    "                                 values='step_id', \n",
    "                                 aggfunc='count', \n",
    "                                 index='user_id', \n",
    "                                 fill_value=0) \\\n",
    "                                .reset_index() \\\n",
    "                                .rename_axis('', axis=1)\n",
    "    events_data = events_data.pivot_table(columns='action', \n",
    "                             values='step_id', \n",
    "                             aggfunc='count', \n",
    "                             index='user_id',\n",
    "                             fill_value=0) \\\n",
    "                             .reset_index() \\\n",
    "                             .rename_axis('', axis=1)\n",
    "    \n",
    "    #Объединяем\n",
    "    merged_df = submission_data.merge(events_data, \n",
    "                                           on='user_id', \n",
    "                                           how='outer') \\\n",
    "                                           .fillna(0)\n",
    "    \n",
    "    #Проверяем что все пользователи на остались в данных\n",
    "    assert events_data.user_id.nunique() == merged_df.user_id.nunique()\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(submission_data, threshold=40):\n",
    "    '''Создаем таргет для расчета что будет считаться успешным прохождением теста. По умолчанию принимаем 40 правильных ответов как условие прохождения\n",
    "    Значениsubmission_data_test['correct_num'].hist(bins=50)\n",
    "    '''\n",
    "\n",
    "    #Создаем колонку с количеством правильных ответов\n",
    "    submission_data = submission_data[submission_data['submission_status'] == 'correct'].groupby('user_id') \\\n",
    "                                            .agg({'submission_status':'count'}) \\\n",
    "                                            .reset_index()  \\\n",
    "                                            .rename({'submission_status':'correct_num'}, axis=1)\n",
    "    \n",
    "    #Фильтруем по ранее созданной колонке\n",
    "    submission_data['passed_course'] = (submission_data['correct_num'] > threshold).astype('int')\n",
    "    return submission_data.drop('correct_num', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_features(event_data):\n",
    "    '''Создаем колонку часов посвященных на обучению'''\n",
    "    event_data['day'] = event_data['timestamp'].astype('datetime64[s]').dt.date\n",
    "    event_data['date'] = event_data['timestamp'].astype('datetime64[s]')\n",
    "\n",
    "    event_data = event_data.groupby('user_id') \\\n",
    "                                    .agg({'date':['max', 'min'], 'day':'nunique'}) \\\n",
    "                                    .rename(columns={'nunique':'days'}) \\\n",
    "                                    .droplevel(0, axis=1)\n",
    "    event_data['hours'] = (event_data['max'] - event_data['min']).astype('timedelta64[h]')\n",
    "\n",
    "    return event_data.drop(['max', 'min'], axis=1).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tries_feature(submission_data):\n",
    "    submission_data = submission_data.groupby('user_id', as_index=False) \\\n",
    "                                    .agg({'step_id':'nunique'}) \\\n",
    "                                    .rename({'step_id':'steps_tried'}, axis=1)\n",
    "    return submission_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_ratio(submission_data):\n",
    "    '''Добавляем колонку соотношения верных и неверных ответов пользователя'''\n",
    "    #Группируем и создаем признак\n",
    "    submission_data = submission_data.pivot_table(index='user_id', columns='submission_status', values='step_id', aggfunc='count', fill_value=0).reset_index()\n",
    "    submission_data['correct_ratio'] = submission_data['correct'] / (submission_data['correct'] + submission_data['wrong'])\n",
    "    return submission_data.drop(['correct', 'wrong'], axis=1).rename_axis('', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(submission_data, events_data):\n",
    "    '''Функция для формирования Х и у датасетов'''\n",
    "    # Фильтруем данные по первым 2 дням обучения для каждого студента\n",
    "    submission_data = filtered_data(submission_data)\n",
    "    events_data = filtered_data(events_data)\n",
    "\n",
    "    # Добавляем базовые признакми и объединяем в единую таблицу\n",
    "    merged_df = create_base_feature(submission_data, events_data=events_data)\n",
    "\n",
    "    #Создаем целевую переменную Y\n",
    "    temp_y = create_target(submission_data, threshold=40)\n",
    "\n",
    "    #Создаем доп признаки по времени и соотношению правильных/неправильных ответов\n",
    "    time_column = time_features(events_data)\n",
    "    ratio_features = correct_ratio(submission_data)\n",
    "\n",
    "    #Объединяем с основной таблицей дополнительные вычисленные признаки\n",
    "    merged_df = merged_df.merge(time_column, on='user_id', how='outer').fillna(0)\n",
    "    merged_df = merged_df.merge(ratio_features, on='user_id', how='outer').fillna(0)\n",
    "    merged_df = merged_df.merge(temp_y, on='user_id', how='outer').fillna(0)\n",
    "\n",
    "    #Создаем целевую переменную X\n",
    "    y = merged_df['passed_course'].map(int)\n",
    "    X = merged_df.drop(columns='passed_course')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_df(submission_data, events_data):\n",
    "    '''Функция для формирования Х и у датасетов'''\n",
    "    # Фильтруем данные по первым 2 дням обучения для каждого студента\n",
    "    submission_data = filtered_data(submission_data)\n",
    "    events_data = filtered_data(events_data)\n",
    "\n",
    "    # Добавляем базовые признакми и объединяем в единую таблицу\n",
    "    merged_df = create_base_feature(submission_data, events_data)\n",
    "\n",
    "    #Создаем целевую переменную Y\n",
    "    y = create_target(submission_data, threshold=40)\n",
    "\n",
    "    #Создаем доп признаки по времени и соотношению правильных/неправильных ответов\n",
    "    time_column = time_features(events_data)\n",
    "    ratio_features = correct_ratio(submission_data)\n",
    "\n",
    "    #Объединяем с основной таблицей дополнительные вычисленные признаки\n",
    "    merged_df = merged_df.merge(time_column, on='user_id', how='outer').fillna(0)\n",
    "    X = merged_df.merge(ratio_features, on='user_id', how='outer').fillna(0)\n",
    "\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание треннировочного и тестового датасетов\n",
    "X_train, y = create_df(submission_data_train, events_data_train)\n",
    "#X_test = create_test_df(submission_data_test, events_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_with_grid(train_data, y, size=0.20):\n",
    "    \n",
    "    \"\"\"Поиск наилучших параметров для RandomForest, обучаясь на тренировочной выборке.\n",
    "    Можно изменять или добавлять различные параметры. Может долго вычисляться.\"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data, y, test_size=size, random_state=42)\n",
    "    \n",
    "    param_grid = {'randomforestclassifier__n_estimators': range(20, 51, 3), \n",
    "                  'randomforestclassifier__max_depth': range(5, 14)}\n",
    "    \n",
    "    pipe = make_pipeline(RandomForestClassifier())\n",
    "    pipe.fit(X_train, y_train)\n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(f\"Наилучшие параметры: {grid.best_params_}\")\n",
    "    \n",
    "    ypred_prob = grid.predict_proba(X_test)\n",
    "    \n",
    "    roc_score = roc_auc_score(y_test, ypred_prob[:, 1])\n",
    "    score = grid.score(X_test, y_test)\n",
    "    print(f\"Правильность на тестовом наборе: {score:.2f}\")\n",
    "    print(roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие параметры: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__n_estimators': 20}\n",
      "Правильность на тестовом наборе: 1.00\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "model = random_with_grid(X_train, y)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
